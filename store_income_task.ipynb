{"cells":[{"cell_type":"markdown","metadata":{"id":"lqt_yzRy16Wj"},"source":["## Compulsory Task \n","\n","In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Importing libraries.\n","import pandas as pd\n","import numpy as np\n","import fuzzywuzzy\n","from fuzzywuzzy import process\n","import chardet\n","from datetime import datetime"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>United States/</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>Britain</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>United States</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>Britain/</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     store_name         store_email  department        income  \\\n","id                                                                              \n","1    Cullen/Frost Bankers, Inc.                 NaN    Clothing  $54438554.24   \n","2           Nordson Corporation                 NaN       Tools  $41744177.01   \n","3         Stag Industrial, Inc.                 NaN      Beauty  $36152340.34   \n","4           FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   $8928350.04   \n","5   Mercantile Bank Corporation                 NaN        Baby  $33552742.32   \n","\n","   date_measured          country  \n","id                                 \n","1       4-2-2006   United States/  \n","2       4-1-2006          Britain  \n","3      12-9-2003    United States  \n","4       8-5-2006         Britain/  \n","5      21-1-1973   United Kingdom  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Loading up 'store_income_data.csv'.\n","df_store_income = pd.read_csv(\n","    'store_income_data_task.csv', \n","    index_col=0,\n","    header=0\n",")\n","df_store_income.head()"]},{"cell_type":"markdown","metadata":{"id":"ItqLwumA16Wr"},"source":["1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Unique values in the country column:77\n"]},{"data":{"text/plain":["array(['United States/', 'Britain', ' United States', 'Britain/',\n","       ' United Kingdom', 'U.K.', 'SA ', 'U.K/', 'America',\n","       'United Kingdom', nan, 'united states', ' S.A.', 'England ', 'UK',\n","       'S.A./', 'ENGLAND', 'BRITAIN', 'U.K', 'U.K ', 'America/', 'SA.',\n","       'S.A. ', 'u.k', 'uk', ' ', 'UK.', 'England/', 'england',\n","       ' Britain', 'united states of america', 'UK/', 'SA/', 'SA',\n","       'England.', 'UNITED KINGDOM', 'America.', 'S.A..', 's.a.', ' U.K',\n","       ' United States of America', 'Britain ', 'England', ' SA',\n","       'United States of America.', 'United States of America/',\n","       'United States.', 's. africasouth africa', ' England',\n","       'United Kingdom ', 'United States of America ', ' UK',\n","       'united kingdom', 'AMERICA', 'America ',\n","       'UNITED STATES OF AMERICA', ' S. AfricaSouth Africa', 'america',\n","       'S. AFRICASOUTH AFRICA', 'Britain.', '/', 'United Kingdom.',\n","       'United States', ' America', 'UNITED STATES', 'sa',\n","       'United States of America', 'UK ', 'United States ',\n","       'S. AfricaSouth Africa/', 'S.A.', 'United Kingdom/',\n","       'S. AfricaSouth Africa ', 'S. AfricaSouth Africa.',\n","       'S. AfricaSouth Africa', '.', 'britain'], dtype=object)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Unique values in the \"country\" column.\n","countries = df_store_income['country'].unique()\n","print(f\"\\nUnique values in the country column:{len(countries)}\")\n","countries"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Unique values in the country column:37\n"]},{"data":{"text/plain":["array(['united states/', 'britain', 'united states', 'britain/',\n","       'united kingdom', 'u.k.', 'sa', 'u.k/', 'america', nan, 's.a.',\n","       'england', 'uk', 's.a./', 'u.k', 'america/', 'sa.', '', 'uk.',\n","       'england/', 'united states of america', 'uk/', 'sa/', 'england.',\n","       'america.', 's.a..', 'united states of america.',\n","       'united states of america/', 'united states.',\n","       's. africasouth africa', 'britain.', '/', 'united kingdom.',\n","       's. africasouth africa/', 'united kingdom/',\n","       's. africasouth africa.', '.'], dtype=object)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Converting to the lower case.\n","df_store_income['country'] = df_store_income['country'].str.lower()\n","# Removing tailing whitespaces. \n","df_store_income['country'] = df_store_income['country'].str.strip()\n","\n","# Unique values in the \"country\" column.\n","countries = df_store_income['country'].unique()\n","print(f\"\\nUnique values in the country column:{len(countries)}\")\n","countries"]},{"cell_type":"markdown","metadata":{"id":"P6dcDc4P16Ws"},"source":["2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>united states/</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>britain</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>united states</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>britain/</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>united kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     store_name         store_email  department        income  \\\n","id                                                                              \n","1    Cullen/Frost Bankers, Inc.                 NaN    Clothing  $54438554.24   \n","2           Nordson Corporation                 NaN       Tools  $41744177.01   \n","3         Stag Industrial, Inc.                 NaN      Beauty  $36152340.34   \n","4           FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   $8928350.04   \n","5   Mercantile Bank Corporation                 NaN        Baby  $33552742.32   \n","\n","   date_measured         country  \n","id                                \n","1       4-2-2006  united states/  \n","2       4-1-2006         britain  \n","3      12-9-2003   united states  \n","4       8-5-2006        britain/  \n","5      21-1-1973  united kingdom  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Getting the top 10 closest matches to \"united kingdom\".\n","matches = fuzzywuzzy.process.extract(\n","    \"uk\", \n","    countries, \n","    limit=20, \n","    scorer=fuzzywuzzy.fuzz.token_sort_ratio\n",")\n","\n","# Inspecting matches.\n","matches\n","df_store_income.head()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def replace_matches_in_column(df, column, string_to_match, min_ratio =65):\n","    \"\"\"\n","    # Function to replace rows in the provided column of the provided \n","    # DataFrame that match the provided string above the provided ratio\n","    # with the provided string.\n","    \"\"\"\n","    # Getting a list of unique strings.\n","    strings = df[column].unique()\n","    # Getting the top 10 closest matches to our input string.\n","    matches = fuzzywuzzy.process.extract(\n","        string_to_match, \n","        strings, limit=20, \n","        scorer=fuzzywuzzy.fuzz.token_sort_ratio\n","    )\n","\n","    # Only getting matches with a ratio > 65.\n","    close_matches = [\n","        matches[0] for matches in matches if matches[1] >= min_ratio\n","    ]\n","    # Getting the rows of all the close matches in our dataframe.\n","    rows_with_matches = df[column].isin(close_matches)\n","    # Replacing all rows with close matches with the input matches.\n","    df.loc[rows_with_matches, column] = string_to_match\n","    \n","    # Verifiyng when the function is done.\n","    print(\"All done!\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["All done!\n","All done!\n","All done!\n","All done!\n","All done!\n","All done!\n","All done!\n","All done!\n","All done!\n","All done!\n","All done!\n"]}],"source":["# Calling the function \" replace_matches_in_column()\".\n","# List of strings to match.\n","strings_to_match = [\n","    \"united kingdom\", \n","    \"united states\", \n","    \"united states of america\", \n","    \"south africa\",\n","    \"uk\", \n","    \"britain\", \n","    \"england\", \n","    \"s.a\", \n","    \"sa\", \n","    \"u.k\", \n","    \"america\", \n","    #\"s. africasouth Africa\"\n","]\n","\n","# Iterating through the list and calling replace_matches_in_column \n","# function.\n","for string in strings_to_match:\n","    replace_matches_in_column(\n","        df=df_store_income, \n","        column='country', \n","        string_to_match=string\n","    )"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Unique values in the country column:14\n"]},{"data":{"text/plain":["array(['united states of america', 'britain', 'united kingdom', 'u.k',\n","       'sa', 'america', nan, 's.a', 'england', 'uk', '', 'south africa',\n","       '/', '.'], dtype=object)"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# After cleaning unique values in the \"country\" column.\n","countries = df_store_income['country'].unique()\n","print(f\"\\nUnique values in the country column:{len(countries)}\")\n","countries"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Replacing the country names with United Kingdom, United States and \n","# South Africa.\n","replace_with_countries_name = {\n","    'united states' : 'United States',\n","    'america' : 'United States',\n","    'united states of america' : 'United States',\n","    'britain' : 'United Kingdom',\n","    'united kingdom' : 'United Kingdom',\n","    'u.k' : 'United Kingdom',\n","    'england' : 'United Kingdom',\n","    'uk' : 'United Kingdom',\n","    'sa' : 'South Africa',\n","    's.a' : 'South Africa',\n","    ''  : None,\n","    '/' : None,\n","    '.' : None,\n","    'south africa': 'South Africa'\n","}\n","\n","df_store_income.replace(replace_with_countries_name, inplace=True)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['United States' 'United Kingdom' 'South Africa']\n"]}],"source":["# Replacing missing values by mode.\n","mode_of_country = df_store_income['country'].mode()[0]\n","df_store_income['country'] = df_store_income['country'].fillna(mode_of_country)\n","print(df_store_income['country'].unique())"]},{"cell_type":"markdown","metadata":{"id":"UJZDMTwP16Ws"},"source":["3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"gMJbN84P16Wt"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","      <th>days_ago</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>United States</td>\n","      <td>4-2-2006</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>United Kingdom</td>\n","      <td>4-1-2006</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>United States</td>\n","      <td>12-9-2003</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>United Kingdom</td>\n","      <td>8-5-2006</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>United Kingdom</td>\n","      <td>21-1-1973</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     store_name         store_email  department        income  \\\n","id                                                                              \n","1    Cullen/Frost Bankers, Inc.                 NaN    Clothing  $54438554.24   \n","2           Nordson Corporation                 NaN       Tools  $41744177.01   \n","3         Stag Industrial, Inc.                 NaN      Beauty  $36152340.34   \n","4           FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   $8928350.04   \n","5   Mercantile Bank Corporation                 NaN        Baby  $33552742.32   \n","\n","   date_measured         country   days_ago  \n","id                                           \n","1       4-2-2006   United States   4-2-2006  \n","2       4-1-2006  United Kingdom   4-1-2006  \n","3      12-9-2003   United States  12-9-2003  \n","4       8-5-2006  United Kingdom   8-5-2006  \n","5      21-1-1973  United Kingdom  21-1-1973  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Creating new called column days_ago and copying date_measured column.\n","df_store_income['days_ago'] = df_store_income['date_measured'].copy()\n","df_store_income.head()"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["store_name       object\n","store_email      object\n","department       object\n","income           object\n","date_measured    object\n","country          object\n","days_ago         object\n","dtype: object"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Checking the data type of the columns.\n","df_store_income.dtypes"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","      <th>days_ago</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>2006-02-04</td>\n","      <td>United States</td>\n","      <td>4-2-2006</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>2006-01-04</td>\n","      <td>United Kingdom</td>\n","      <td>4-1-2006</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>2003-09-12</td>\n","      <td>United States</td>\n","      <td>12-9-2003</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>2006-05-08</td>\n","      <td>United Kingdom</td>\n","      <td>8-5-2006</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>1973-01-21</td>\n","      <td>United Kingdom</td>\n","      <td>21-1-1973</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     store_name         store_email  department        income  \\\n","id                                                                              \n","1    Cullen/Frost Bankers, Inc.                 NaN    Clothing  $54438554.24   \n","2           Nordson Corporation                 NaN       Tools  $41744177.01   \n","3         Stag Industrial, Inc.                 NaN      Beauty  $36152340.34   \n","4           FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   $8928350.04   \n","5   Mercantile Bank Corporation                 NaN        Baby  $33552742.32   \n","\n","   date_measured         country   days_ago  \n","id                                           \n","1     2006-02-04   United States   4-2-2006  \n","2     2006-01-04  United Kingdom   4-1-2006  \n","3     2003-09-12   United States  12-9-2003  \n","4     2006-05-08  United Kingdom   8-5-2006  \n","5     1973-01-21  United Kingdom  21-1-1973  "]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Converting date_measured column into datetime format.\n","df_store_income['date_measured'] =  pd.to_datetime(\n","    df_store_income['date_measured'], \n","    format='%d-%m-%Y'\n",")\n","df_store_income.head()"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["dtype('<M8[ns]')"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Checking data type.\n","df_store_income['date_measured'].dtype"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","      <th>days_ago</th>\n","    </tr>\n","    <tr>\n","      <th>id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>2006-02-04</td>\n","      <td>United States</td>\n","      <td>6610</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>2006-01-04</td>\n","      <td>United Kingdom</td>\n","      <td>6641</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>2003-09-12</td>\n","      <td>United States</td>\n","      <td>7486</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>2006-05-08</td>\n","      <td>United Kingdom</td>\n","      <td>6517</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>1973-01-21</td>\n","      <td>United Kingdom</td>\n","      <td>18677</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     store_name         store_email  department        income  \\\n","id                                                                              \n","1    Cullen/Frost Bankers, Inc.                 NaN    Clothing  $54438554.24   \n","2           Nordson Corporation                 NaN       Tools  $41744177.01   \n","3         Stag Industrial, Inc.                 NaN      Beauty  $36152340.34   \n","4           FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   $8928350.04   \n","5   Mercantile Bank Corporation                 NaN        Baby  $33552742.32   \n","\n","   date_measured         country  days_ago  \n","id                                          \n","1     2006-02-04   United States      6610  \n","2     2006-01-04  United Kingdom      6641  \n","3     2003-09-12   United States      7486  \n","4     2006-05-08  United Kingdom      6517  \n","5     1973-01-21  United Kingdom     18677  "]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Calculating number of days ago that it measured.\n","today = datetime.today() # Current day.\n","\n","df_store_income['days_ago'] = (\n","    today - df_store_income['date_measured']\n",").dt.days\n","df_store_income.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 ('phd')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
